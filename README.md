# Фильтр желтушных новостей

Данная программа представляет собой web-сервис для анализа статей с новостных сайтов. Web-сервис может выступать в роли backend'а для плагина в браузере. Задача плагина к браузеру — просканировать страницу новостного сайта и найти все ссылки на статьи и отправить нашему сервису. Далее сервис получает список ссылок на статьи, парсит содержимое статей, анализирует их и для каждой статьи вычисляет рейтинг "желтушности". Под "желтушной" статьей понимается текст в котором содержатся много экспрессивных слов, ярко-негативных или восторженно-позитивных фраз. После вычисления рейтинга информация передается обратно в плагин и тот отображает рейтинг прямо на странице новостного сайта.  

Пока поддерживается только один новостной сайт - [ИНОСМИ.РУ](https://inosmi.ru/). Для него разработан специальный адаптер, умеющий выделять текст статьи на фоне остальной HTML разметки. Для других новостных сайтов потребуются новые адаптеры, все они будут находиться в каталоге `adapters`. Туда же помещен код для сайта ИНОСМИ.PY: `adapters/inosmi_ru.py`.  

В перспективе можно создать универсальный адаптер, подходящий для всех сайтов, но его разработка будет сложной и потребует дополнительных времени и сил.  

# Как установить

Вам понадобится Python версии 3.7 или старше. Для установки пакетов рекомендуется создать виртуальное окружение.

Первым шагом установите пакеты:

```python3
pip install -r requirements.txt
```

# Как запустить

Запуск сервера:
```python3
python main.py
```

# Как использовать

Для получения рейтинга статей необходимо отправить GET запрос к серверу. Список статей указываем в параметре запроса "__urls__" через запятую.  

 Пример GET запроса со списком статей с ресурса *inosmi.ru*:
 ```
http://127.0.0.1:8080/?urls=https://inosmi.ru/social/20191004/245951541.html, https://inosmi.ru/social/20191008/245982282.html, https://inosmi.ru/science/20191006/245965114.html
 ```

 Нет уверенности, что сервер справится с ситуацией когда в запросе будет передан слишком длинный список url-адресов. Для этого введено ограниение - не более 10 статей для анализа. На запрос со слишком большим количеством статей для анализа сервер ответит статусом 400 Bad Request. В ответе будет JSON с описанием ошибки:
```
{"error": "too many urls in request, should be 10 or less"}
```


# Как запустить тесты

Для тестирования используется [pytest](https://docs.pytest.org/en/latest/), тестами покрыты фрагменты кода сложные в отладке: text_tools.py и адаптеры. Команды для запуска тестов:

```
python -m pytest
```

# Цели проекта

Код написан в учебных целях. Это урок из курса по веб-разработке — [Девман](https://dvmn.org).
